import os
import tempfile
from contextlib import contextmanager
from typing import Any, Dict, Optional
import mlflow
import pandas as pd
import numpy as np
import gc
from mlflow.tracking import MlflowClient

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (
    classification_report,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
import joblib
import cloudpickle
from IPython import get_ipython
from IPython.display import display
import tempfile
from joblib import dump, load
from sklearn.base import BaseEstimator, TransformerMixin
# V√° t·∫°m: n·∫øu thi·∫øu _parameter_constraints th√¨ g√°n m·ªôt dict tr·ªëng
if not hasattr(RandomForestClassifier, "_parameter_constraints"):
    RandomForestClassifier._parameter_constraints = {}
import imblearn, sys
from imblearn.pipeline import Pipeline as ImPipeline
from mlflow.models.signature import infer_signature

# Patch ƒë·ªÉ tr√°nh PicklingError khi dump/load
sys.modules['imblearn.pipeline'] = imblearn.pipeline

class FrequencyEncoder(BaseEstimator, TransformerMixin):
    def __init__(self): 
        self.freq_map = {}
    def fit(self, X, y=None):
        col = X.columns[0] if isinstance(X, pd.DataFrame) else 0
        series = X[col] if isinstance(X, pd.DataFrame) else pd.Series(X[:, 0])
        self.freq_map = series.value_counts(normalize=True).to_dict()
        return self
    def transform(self, X):
        col = X.columns[0] if isinstance(X, pd.DataFrame) else 0
        series = X[col] if isinstance(X, pd.DataFrame) else pd.Series(X[:, 0])
        return series.map(self.freq_map).fillna(0).to_frame()
# Top-level wrapper class (module-level gi√∫p pickle ·ªïn ƒë·ªãnh h∆°n)
class _JoblibPipelineWrapper(mlflow.pyfunc.PythonModel):
    """
    L·ªõp wrapper tu√¢n th·ªß theo chu·∫©n `mlflow.pyfunc.PythonModel`.
    
    N√≥ ƒë√≥ng g√≥i m·ªôt pipeline ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán (l∆∞u b·∫±ng joblib) ƒë·ªÉ ƒë·∫£m b·∫£o
    vi·ªác load v√† predict ho·∫°t ƒë·ªông m·ªôt c√°ch nh·∫•t qu√°n khi tri·ªÉn khai m√¥ h√¨nh
    th√¥ng qua MLflow, ƒë·∫∑c bi·ªát h·ªØu √≠ch khi pipeline ch·ª©a c√°c th√†nh ph·∫ßn ph·ª©c t·∫°p
    ho·∫∑c c√°c th√†nh ph·∫ßn t·ª´ th∆∞ vi·ªán cuML.
    """
    def load_context(self, context):
        from joblib import load
        pipeline_path = context.artifacts["pipeline"]
        self.pipeline = load(pipeline_path)

    def predict(self, context, model_input: pd.DataFrame) -> np.ndarray:
        """
        Ph∆∞∆°ng th·ª©c predict v·ªõi type hints ƒë·ªÉ ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa MLflow.
        """
        return self.pipeline.predict(model_input)

@contextmanager
def _temporarily_disable_cuml_accel():
    """
    Context manager ƒë·ªÉ t·∫°m th·ªùi v√¥ hi·ªáu h√≥a extension `cuml.accel` trong m√¥i tr∆∞·ªùng IPython.
    
    Vi·ªác n√†y c·∫ßn thi·∫øt ƒë·ªÉ tr√°nh l·ªói `PicklingError` khi l∆∞u (serializing) c√°c ƒë·ªëi t∆∞·ª£ng
    t·ª´ th∆∞ vi·ªán cuML b·∫±ng `joblib` ho·∫∑c `cloudpickle`. Extension s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông
    t·∫£i l·∫°i sau khi tho√°t kh·ªèi kh·ªëi `with`.
    """
    """
    Unload cuml.accel (if running in IPython) then yield.
    After yield, reload it if we unloaded it.
    Works in Jupyter/Colab. If not in IPython, does nothing.
    """
    ip = get_ipython()
    unloaded = False
    if ip is not None:
        try:
            # try to unload (no error if not loaded)
            ip.run_line_magic("unload_ext", "cuml.accel")
            unloaded = True
            print("[info] cuml.accel unloaded for safe pickling...")
        except Exception:
            # either not loaded or unload failed ‚Äî ignore
            unloaded = False
    
    try:
        yield
    finally:
        if ip is not None and unloaded:
            try:
                ip.run_line_magic("load_ext", "cuml.accel")
                print("[info] cuml.accel reloaded.")
            except Exception:
                pass
class AdvancedModelTuner:
    """
    Pipeline chu·∫©n cho ML experiment:
    - ColumnTransformer input s·∫µn
    - T√πy ch·ªçn sampler (SMOTE/ADASYN)
    - GridSearchCV tuning
    - In data ƒë√£ x·ª≠ l√Ω, metrics, confusion matrix
    - V·∫Ω feature importance n·∫øu c√≥
    Note: d√πng gpu th√¨ ƒë·ª´ng truy·ªÅn n_jobs.
    """
    """
    M·ªôt class ƒëa nƒÉng ƒë·ªÉ t·ª± ƒë·ªông h√≥a quy tr√¨nh th·ª≠ nghi·ªám Machine Learning.

    Class n√†y ƒë√≥ng g√≥i c√°c b∆∞·ªõc ph·ªï bi·∫øn nh∆∞ x√¢y d·ª±ng pipeline, tinh ch·ªânh
    si√™u tham s·ªë, ƒë√°nh gi√° m√¥ h√¨nh v√† ghi l·∫°i k·∫øt qu·∫£ b·∫±ng MLflow. N√≥ ƒë∆∞·ª£c
    thi·∫øt k·∫ø ƒë·ªÉ ho·∫°t ƒë·ªông linh ho·∫°t: c√≥ th·ªÉ t·ª± qu·∫£n l√Ω m·ªôt MLflow run ho√†n ch·ªânh
    ho·∫∑c t·∫°o m·ªôt run con (nested run) b√™n trong m·ªôt run ƒëang ho·∫°t ƒë·ªông.

    Thu·ªôc t√≠nh (Attributes):
        search_strategy (Any): ƒê·ªëi t∆∞·ª£ng chi·∫øn l∆∞·ª£c t√¨m ki·∫øm (vd: GridSearchCV).
        preprocessor (Any): B·ªô ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (vd: ColumnTransformer).
        sampler (Optional[Any]): ƒê·ªëi t∆∞·ª£ng l·∫•y m·∫´u ƒë·ªÉ x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng (vd: SMOTE).
        experiment_name (Optional[str]): T√™n c·ªßa MLflow experiment.
        manage_run (bool): C·ªù ƒë·ªÉ b·∫≠t/t·∫Øt vi·ªác qu·∫£n l√Ω run t·ª± ƒë·ªông.
        pipeline (Optional[Pipeline]): Pipeline ho√†n ch·ªânh ƒë∆∞·ª£c x√¢y d·ª±ng trong `fit`.
        best_estimator_ (Optional[Pipeline]): Pipeline t·ªët nh·∫•t ƒë∆∞·ª£c t√¨m th·∫•y sau khi tuning.
        train_results_ (Optional[Dict]): T·ª´ ƒëi·ªÉn ch·ª©a c√°c metrics tr√™n t·∫≠p hu·∫•n luy·ªán.
        test_results_ (Optional[Dict]): T·ª´ ƒëi·ªÉn ch·ª©a c√°c metrics tr√™n t·∫≠p ki·ªÉm tra.
    """
    def __init__(self, 
                 preprocessor: Any, 
                 model: Optional[Any] = None,
                 search_strategy: Optional[Any] = None,
                 
                 sampler: Optional[Any] = None, 
                 experiment_name=None,
                 manage_run: bool = True,
                 auto_cleanup: bool = True,
                 pip_requirements: Optional[list] = None,  
                 conda_env: Optional[str] = None
                 ):
        

        """
        Kh·ªüi t·∫°o AdvancedModelTuner.

        Args:
            model (Optional[Any]): Model c∆° s·ªü c·∫ßn hu·∫•n luy·ªán (vd: XGBClassifier(), LogisticRegression()). (model or search)
            preprocessor (Any): B·ªô ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (vd: ColumnTransformer).
            search_strategy (Optional[Any]): M·ªôt instance ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh c·ªßa m·ªôt l·ªõp t√¨m ki·∫øm
                                           (vd: GridSearchCV). N·∫øu l√† None, model s·∫Ω ƒë∆∞·ª£c fit
                                           m√† kh√¥ng c·∫ßn tuning.
            sampler (Optional[Any], optional): M·ªôt instance c·ªßa m·ªôt l·ªõp sampler t·ª´
                                               `imblearn` (vd: SMOTE). M·∫∑c ƒë·ªãnh l√† None.
            experiment_name (Optional[str], optional): T√™n c·ªßa MLflow experiment. N·∫øu kh√¥ng
                                                       cung c·∫•p, s·∫Ω d√πng "default_experiment".
            manage_run (bool, optional): N·∫øu l√† True (m·∫∑c ƒë·ªãnh), class s·∫Ω t·ª± ƒë·ªông qu·∫£n l√Ω
                                         vi·ªác b·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c MLflow run. N·∫øu False,
                                         ng∆∞·ªùi d√πng ph·∫£i t·ª± qu·∫£n l√Ω run t·ª´ b√™n ngo√†i.
                                         
                                         
                        -->ch·ªâ false n·∫øu l·ªìng th√¥i v√† ch·ªâ c√≥ 1 run , c√≤n n·∫øu l·ªìng m√† true th√¨ l√† run l·ªìng run
                        FALSE V√Ä KO L·ªíNG TH√å KO LOG.
        """
        self.search_strategy = search_strategy
        self.model=model
        self.experiment_name=experiment_name
        self.sampler = sampler
        self.preprocessor = preprocessor
        
        
        self.manage_run = manage_run
        self.auto_cleanup = auto_cleanup
        
        self.pipeline: Optional[Pipeline] = None
        self.best_estimator_: Optional[Pipeline] = None
        self.train_results_: Optional[Dict] = None
        self.test_results_: Optional[Dict] = None
        
        
        if pip_requirements and conda_env:
            raise ValueError("Ch·ªâ c√≥ th·ªÉ cung c·∫•p 'pip_requirements' ho·∫∑c 'conda_env', kh√¥ng ph·∫£i c·∫£ hai.")
        self.pip_requirements = pip_requirements
        self.conda_env = conda_env
        
        
        self.run_ = None# Th√™m thu·ªôc t√≠nh ƒë·ªÉ gi·ªØ run context
        
    def __enter__(self):
        """B·∫Øt ƒë·∫ßu MLflow run khi v√†o kh·ªëi l·ªánh `with`.
            T·ª± ƒë·ªông ph√°t hi·ªán v√† t·∫°o run l·ªìng nhau n·∫øu c·∫ßn
        """

        if not self.manage_run:
            return self

        # Ki·ªÉm tra xem c√≥ run n√†o ƒëang ho·∫°t ƒë·ªông kh√¥ng
        if mlflow.active_run():
            self._is_nested = True
            print("--- Active run detected. Creating a nested run... ---")
            # N·∫øu c√≥, t·∫°o m·ªôt run con (nested)
            self.run_ = mlflow.start_run(run_name=self.get_run_name(), nested=True)
        else:
            self._is_nested = False
            print("--- No active run. Creating a new parent run... ---")
            # N·∫øu kh√¥ng, t·∫°o m·ªôt run cha m·ªõi
            mlflow.set_experiment(self.experiment_name or "default_experiment")
            self.run_ = mlflow.start_run(run_name=self.get_run_name())
        return self
    def cleanup(self):
        """
        X√≥a c√°c thu·ªôc t√≠nh chi·∫øm nhi·ªÅu b·ªô nh·ªõ v√† g·ªçi garbage collector.
        H·ªØu √≠ch ƒë·ªÉ gi·∫£i ph√≥ng RAM v√† VRAM (v·ªõi cuML).
        """
        print("\n" + "="*30)
        print("üßπ B·∫Øt ƒë·∫ßu t·ª± ƒë·ªông d·ªçn d·∫πp b·ªô nh·ªõ...")
        
        # Danh s√°ch c√°c thu·ªôc t√≠nh c·∫ßn x√≥a
        attrs_to_delete = [
            'best_estimator_',
            'search_strategy',
            'pipeline',
            'train_results_',
            'test_results_',
            'model' # X√≥a c·∫£ model g·ªëc n·∫øu c√≥
        ]
        
        for attr in attrs_to_delete:
            if hasattr(self, attr):
                delattr(self, attr)
                print(f"   -> ƒê√£ x√≥a self.{attr}")
        
        # G·ªçi garbage collector
        gc.collect()
        print("üëç D·ªçn d·∫πp ho√†n t·∫•t. B·ªô nh·ªõ ƒë√£ ƒë∆∞·ª£c gi·∫£i ph√≥ng.")
        print("="*30)
    def __exit__(self, exc_type, exc_val, exc_tb):
        """K·∫øt th√∫c MLflow run khi ra kh·ªèi kh·ªëi l·ªánh `with`."""
        if self.manage_run and self.run_ is not None:
            mlflow.end_run()
            if self._is_nested:
                print("--- Nested run finished. ---")
            else:
                print("--- Parent run finished. ---")
        if self.auto_cleanup:
            self.cleanup()
    
        

    def get_run_name(self):
        """
        L·∫•y t√™n run m·ªôt c√°ch linh ho·∫°t d·ª±a tr√™n model ho·∫∑c search_strategy.
        """
        model_obj = None
        suffix = "run"

        if self.search_strategy:
            # ∆Øu ti√™n l·∫•y model t·ª´ search_strategy n·∫øu c√≥
            model_obj = self.search_strategy.estimator
            suffix = "tuning"
        elif self.model:
            # N·∫øu kh√¥ng, l·∫•y t·ª´ model c∆° s·ªü
            model_obj = self.model
            suffix = "training"
        
        if model_obj is None:
            return "Untitled_Run" # Tr·∫£ v·ªÅ t√™n m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng c√≥ model

        # L·∫•y t√™n class t·ª´ model object
        if hasattr(model_obj, 'steps'):
             # N·∫øu model l√† m·ªôt pipeline, l·∫•y t√™n c·ªßa b∆∞·ªõc cu·ªëi c√πng
             model_name = model_obj.steps[-1][1].__class__.__name__
        else:
             model_name = model_obj.__class__.__name__
             
        return f"{model_name}_{suffix}"
    def _prepare_param_grid(self):
        """
        H√†m n·ªôi b·ªô ƒë·ªÉ t·ª± ƒë·ªông th√™m ti·ªÅn t·ªë 'clf__' v√†o c√°c tham s·ªë 
        ch∆∞a c√≥ ti·ªÅn t·ªë trong l∆∞·ªõi t√¨m ki·∫øm.
        """
        if hasattr(self.search_strategy, 'param_grid'):
            param_key = 'param_grid'
        elif hasattr(self.search_strategy, 'param_distributions'):
            param_key = 'param_distributions'
        elif hasattr(self.search_strategy, 'search_spaces'):
            param_key = 'search_spaces'
        else:
            raise AttributeError(
                "Kh√¥ng t√¨m th·∫•y thu·ªôc t√≠nh l∆∞·ªõi tham s·ªë (param_grid, "
                "param_distributions, or search_spaces) trong search_strategy."
            )
        original_params = getattr(self.search_strategy, param_key)

        new_params = {}
        for k, v in original_params.items():
            if '__' not in k:
                new_params['clf__' + k] = v
            else:
                new_params[k] = v
        
        setattr(self.search_strategy, param_key, new_params)
        print("[info] Parameter grid has been prepared with prefixes.")
    def fit(self, X_train: pd.DataFrame, y_train: pd.Series,**fit_params):
        """
        X√¢y d·ª±ng pipeline, th·ª±c hi·ªán t√¨m ki·∫øm si√™u tham s·ªë v√† l∆∞u l·∫°i k·∫øt qu·∫£.

        C√°c b∆∞·ªõc th·ª±c hi·ªán:
        1. L·∫Øp r√°p pipeline ho√†n ch·ªânh t·ª´ `preprocessor`, `sampler` (n·∫øu c√≥), v√† model.
        2. C·∫•u h√¨nh l·∫°i `search_strategy` ƒë·ªÉ ho·∫°t ƒë·ªông v·ªõi pipeline n√†y.
        3. Ch·∫°y `fit` c·ªßa `search_strategy` tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán.
        4. L∆∞u l·∫°i estimator t·ªët nh·∫•t (`best_estimator_`).
        5. Log c√°c tham s·ªë v√† score t·ªët nh·∫•t v√†o MLflow (n·∫øu `manage_run`=True).
        6. Log model t·ªët nh·∫•t v√†o MLflow.
        7. In k·∫øt qu·∫£ t√≥m t·∫Øt v√† hi·ªÉn th·ªã m·ªôt v√†i d√≤ng d·ªØ li·ªáu ƒë√£ qua x·ª≠ l√Ω.

        Args:
            X_train (pd.DataFrame): DataFrame ch·ª©a c√°c ƒë·∫∑c tr∆∞ng c·ªßa t·∫≠p hu·∫•n luy·ªán.
            y_train (pd.Series): Series ch·ª©a nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán.

        Returns:
            AdvancedModelTuner: Tr·∫£ v·ªÅ ch√≠nh instance c·ªßa class ƒë·ªÉ c√≥ th·ªÉ g·ªçi chaining.
        """
        if self.search_strategy:
            base_model=self.search_strategy.estimator
            
            steps = [('preprocessor', self.preprocessor)]
            if self.sampler:
                steps.append(('sampler', self.sampler))
            steps.append(('clf', base_model))

            self.pipeline = ImPipeline(steps)
            self.search_strategy.estimator = self.pipeline
            
            
            self._prepare_param_grid()

            print("B·∫Øt ƒë·∫ßu qu√° tr√¨nh tuning...")
            

            self.search_strategy.fit(X_train, y_train, **fit_params)
            self.best_estimator_ = self.search_strategy.best_estimator_
            
            ######### LOGGING TR·ª∞C TI·∫æP
            best_params = {k.replace('clf__',''):v for k,v in self.search_strategy.best_params_.items()}
            # Log v√†o MLflow (ch·ªâ log n·∫øu run ƒëang ƒë∆∞·ª£c qu·∫£n l√Ω)
            if self.manage_run:
                mlflow.log_params(best_params)
                mlflow.log_metric("best_cv_score", self.search_strategy.best_score_)
                
                
                # Log model
                self.log_best_model(X_train.dropna())
        
        ###########     
        else:
            # --- PH·∫¶N 2: LOGIC FIT B√åNH TH∆Ø·ªúNG (KHI KH√îNG C√ì SEARCH) ---
            print("Kh√¥ng c√≥ search strategy, ti·∫øn h√†nh fit model b√¨nh th∆∞·ªùng...")
            
            # Gi·∫£ ƒë·ªãnh b·∫°n c√≥ self.model khi search_strategy=None
            if not hasattr(self, 'model'):
                raise AttributeError("Khi 'search_strategy' l√† None, instance ph·∫£i c√≥ thu·ªôc t√≠nh 'model'.")
            
            base_model = self.model
            
            steps = [('preprocessor', self.preprocessor)]
            if self.sampler:
                steps.append(('sampler', self.sampler))
            steps.append(('clf', base_model))
            
            self.pipeline = ImPipeline(steps)
            
            # Truy·ªÅn fit_params v·ªõi prefix 'clf__' cho b∆∞·ªõc model
            prefixed_fit_params = {f'clf__{k}': v for k, v in fit_params.items()}
            self.pipeline.fit(X_train, y_train, **prefixed_fit_params)
            
            # Pipeline ƒë√£ ƒë∆∞·ª£c fit ch√≠nh l√† estimator t·ªët nh·∫•t
            self.best_estimator_ = self.pipeline
            
            print("\n=== Model ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi tham s·ªë m·∫∑c ƒë·ªãnh ===")
            best_params = base_model.get_params()
            # Log c√°c tham s·ªë ƒë√£ d√πng
            if self.manage_run:
                mlflow.log_params(base_model.get_params())
            self.log_best_model(X_train.dropna())
        if self.search_strategy:
            # Hi·ªÉn th·ªã th√¥ng tin
            print("\n=== Best Parameters ===")
            print(best_params)
            scoring_metric = self.search_strategy.scoring or 'score'
            print(f"Best CV {scoring_metric}: {self.search_strategy.best_score_:.4f}")
            
        
        # Show processed data (1-2 batch)
        fitted_preprocessor = self.best_estimator_.named_steps['preprocessor']
        X_processed = fitted_preprocessor.transform(X_train)
        if isinstance(X_processed, pd.DataFrame):
            display(X_processed.head())
            print(X_processed.describe())
        else:
            # N·∫øu output l√† np.array
            print(pd.DataFrame(X_processed).head())
            print(pd.DataFrame(X_processed).describe())

        return self


    def evaluate(self, X: pd.DataFrame, y: pd.Series, dataset_name: str = 'Test'):
        """
        Metrics + classification report.
        """

        if self.best_estimator_ is not None:
            y_pred = self.best_estimator_.predict(X)
        elif self.model is not None:
            y_pred = self.model.predict(X)
        else:
            # N√©m ra l·ªói n·∫øu kh√¥ng c√≥ model n√†o ƒë·ªÉ d√πng
            raise RuntimeError("Kh√¥ng c√≥ model n√†o ƒë·ªÉ ƒë√°nh gi√°. Vui l√≤ng ch·∫°y fit() tr∆∞·ªõc.")
        print(f"\n=== Evaluation on {dataset_name} ===")
        print(classification_report(y, y_pred, digits=4))
        results = {
            "accuracy": accuracy_score(y, y_pred),
            "precision": precision_score(y, y_pred, average='weighted'),
            "recall": recall_score(y, y_pred, average='weighted'),
            "f1": f1_score(y, y_pred, average='weighted')
        }
        ####### LOGGING TR·ª∞C TI·∫æP V·ªöI PREFIX
        mlflow.log_metrics({f"{dataset_name.lower()}_{k}": v for k, v in results.items()})
        #######
        return results

    def evaluate_train_test(self, X_train, y_train, X_test, y_test):
        self.train_results_ = self.evaluate(X_train, y_train, 'Train')
        self.test_results_ = self.evaluate(X_test, y_test, 'Test')
        print(f"\n--- Summary ---")
        print(f"Train F1: {self.train_results_['f1']:.4f}")
        print(f"Test F1:  {self.test_results_['f1']:.4f}")

    def plot_confusion_matrix(self, X, y, dataset_name='Test'):
        import matplotlib.pyplot as plt
        import seaborn as sns
        from sklearn.metrics import confusion_matrix
        if self.best_estimator_ is not None:
            y_pred = self.best_estimator_.predict(X)
        elif self.model is not None:
            y_pred = self.model.predict(X)
        else:
            # N√©m ra l·ªói n·∫øu kh√¥ng c√≥ model n√†o ƒë·ªÉ d√πng
            raise RuntimeError("Kh√¥ng c√≥ model n√†o ƒë·ªÉ ƒë√°nh gi√°. Vui l√≤ng ch·∫°y fit() tr∆∞·ªõc.")
        cm = confusion_matrix(y, y_pred)
        plt.figure(figsize=(8,6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.title(f'Confusion Matrix - {dataset_name}')
        # plt.show()

    def plot_feature_importance(self):
        """
        V·∫Ω feature importance n·∫øu model c√≥ .feature_importances_ ho·∫∑c .coef_
        """
        import matplotlib.pyplot as plt
        import seaborn as sns
        from sklearn.metrics import confusion_matrix
        model = self.best_estimator_.named_steps['clf'] or self.model
        try:
            if hasattr(model, 'feature_importances_'):
                importances = model.feature_importances_
            elif hasattr(model, 'coef_'):
                importances = model.coef_.ravel()
            else:
                print("Model kh√¥ng c√≥ feature_importances_ ho·∫∑c coef_")
                return
            # L·∫•y t√™n feature t·ª´ preprocessor
            feature_names = []
            preprocessor = self.best_estimator_.named_steps['preprocessor']

            for name, trans, cols in preprocessor.transformers_:
                if hasattr(trans, 'named_steps'):
                    # Pipeline trong ColumnTransformer
                    last_step = list(trans.named_steps.values())[-1]
                    if hasattr(last_step, 'get_feature_names_out'):
                        feature_names.extend(last_step.get_feature_names_out(cols))
                    else:
                        feature_names.extend(cols)
                else:
                    feature_names.extend(cols)
            df = pd.DataFrame({'feature': feature_names, 'importance': importances})
            df = df.sort_values('importance', ascending=False)
            # ===================

            # 1. T·∫°o figure v√† axes m·ªôt c√°ch t∆∞·ªùng minh
            fig, ax = plt.subplots(figsize=(10, 8))
            
            # 2. V·∫Ω bi·ªÉu ƒë·ªì tr√™n axes ƒë√£ t·∫°o
            sns.barplot(data=df, x='importance', y='feature', ax=ax)
            ax.set_title('Top 20 Feature Importances')
            ax.set_xlabel('Importance')
            ax.set_ylabel('Feature')
            fig.tight_layout() # CƒÉn ch·ªânh cho ƒë·∫πp

            # 3. LOG BI·ªÇU ƒê·ªí V√ÄO MLFLOW
            mlflow.log_figure(fig, "feature_importance.png")
            
            # 4. Hi·ªÉn th·ªã v√† d·ªçn d·∫πp
            # plt.show()
            plt.close(fig) 
            # ===================

        except Exception as e:
            print("Error plotting feature importance:", e)

    def get_cv_results_df(self):
        if not hasattr(self.search_strategy, 'cv_results_') :
            print("The search strategy has not been fitted or does not have cv_results_.")
            return None
        return pd.DataFrame(self.search_strategy.cv_results_)

    def save_pipeline(self, filepath: str):
        if self.best_estimator_ is None and self.model is None:
            raise RuntimeError("Fit tr∆∞·ªõc khi l∆∞u pipeline.")
        
        dump(self.best_estimator_, filepath) or dump(self.model, filepath)
        print(f"Pipeline saved to {filepath}")

    @staticmethod
    def load_pipeline(filepath: str):
        pipeline = load(filepath)
        print(f"Pipeline loaded from {filepath}")
        return pipeline



    def log_best_model(self, X_sample: 'pd.DataFrame'):
        """
        Logs the model reliably using the mlflow.pyfunc flavor, which offers
        more control and avoids sklearn-specific serialization issues with cuML.
        """
        if self.best_estimator_ is None and self.model is None:
            raise RuntimeError("Fit the model before logging.")

        from mlflow.models import infer_signature
        import mlflow
        import tempfile
        import os
        import joblib

        artifact_name = self.best_estimator_.named_steps['clf'].__class__.__name__ or self.model.__class__.__name__
        registered_model_name = f"{self.experiment_name}_{artifact_name}"
        
        signature = None
        input_example = X_sample.dropna().head()

        if not input_example.empty:
            try:
                # 1. Ch·∫°y predict ƒë·ªÉ l·∫•y output
                if self.best_estimator_ is not None:
                    predictions = self.best_estimator_.predict(input_example)
                elif self.model is not None:
                    predictions = self.model.predict(input_example)
                else:
                    raise RuntimeError("No model found for signature inference.")

                
                # ƒê·ªÉ t∆∞∆°ng th√≠ch, chuy·ªÉn ƒë·ªïi output t·ª´ cuDF sang numpy n·∫øu c·∫ßn
                if 'cudf' in str(type(predictions)):
                    print("[info] Converting cuDF predictions to numpy for signature inference.")
                    predictions = predictions.to_numpy()

                # 2. T·ª± suy lu·∫≠n signature
                signature = infer_signature(input_example, predictions)
                
                print("\n--- Verifying Inferred Signature ---")
                print(signature)
                print("------------------------------------\n")
                print("‚úîÔ∏è Signature inferred successfully.")

            except Exception as e:
                print(f"[warning] Could not manually infer signature: {e}")
        
        print("[info] Using robust mlflow.pyfunc logging strategy...")
        with _temporarily_disable_cuml_accel():
            with tempfile.TemporaryDirectory() as tmpdir:
                pipeline_file = os.path.join(tmpdir, "pipeline.joblib")
                joblib.dump(self.best_estimator_, pipeline_file) or joblib.dump(self.model, pipeline_file)
                utils_abs_path = os.path.abspath(__file__)
                print(f"--- DEBUG: Absolute path for code_paths: {utils_abs_path}") # In ra ƒë·ªÉ ki·ªÉm tra
                # Log model s·ª≠ d·ª•ng pyfunc flavor, c√°ch n√†y r√µ r√†ng v√† t∆∞·ªùng minh h∆°n
                mlflow.pyfunc.log_model(
                    name=artifact_name,
                    code_paths=[utils_abs_path],
                    python_model=_JoblibPipelineWrapper(),
                    artifacts={"pipeline": pipeline_file},
                    registered_model_name=registered_model_name,
                    signature=signature,
                    # **ƒêI·ªÇM S·ª¨A L·ªñI QUAN TR·ªåNG NH·∫§T**
                    # ƒê·∫∑t input_example=None ƒë·ªÉ ngƒÉn MLflow ch·∫°y predict t·ª± ƒë·ªông,
                    # vi·ªác n√†y s·∫Ω tr√°nh ƒë∆∞·ª£c l·ªói `check_is_fitted` v√† `AttributeError`.
                    input_example=None,
                    pip_requirements=self.pip_requirements, 
                    conda_env=self.conda_env                
                )
                print(f"‚úîÔ∏è Logged pipeline via pyfunc + joblib as '{artifact_name}'")

    def fit_discrete(self, 
                    X_train: pd.DataFrame, 
                    y_train: pd.Series,
                    X_val: pd.DataFrame = None, 
                    y_val: pd.Series = None,
                    **fit_params):
        """
        Th·ª±c hi·ªán quy tr√¨nh tuning theo c√°c b∆∞·ªõc r·ªùi r·∫°c, linh ho·∫°t h∆°n.

        Quy tr√¨nh:
        1. Fit b·ªô ti·ªÅn x·ª≠ l√Ω (preprocessor) tr√™n d·ªØ li·ªáu train v√† transform c·∫£ train/val set.
        2. Ch·ªâ tune si√™u tham s·ªë cho model (classifier) tr√™n d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω.
        - N·∫øu validation set ƒë∆∞·ª£c cung c·∫•p, n√≥ s·∫Ω ƒë∆∞·ª£c truy·ªÅn v√†o `fit_params` ƒë·ªÉ
            model c√≥ th·ªÉ t·ª± s·ª≠ d·ª•ng (v√≠ d·ª• cho early stopping).
        3. L·∫Øp r√°p preprocessor ƒë√£ fit v√† model t·ªët nh·∫•t th√†nh m·ªôt pipeline cu·ªëi c√πng
        m√† KH√îNG c·∫ßn hu·∫•n luy·ªán l·∫°i.
        """
        print("--- B·∫Øt ƒë·∫ßu quy tr√¨nh Fit R·ªùi R·∫°c (Discrete Fit) ---")
        
        # === B∆Ø·ªöC 1: TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU ===
        print("üîÑ B∆∞·ªõc 1: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu...")
        # Fit v√† transform tr√™n t·∫≠p train
        X_train_proc = self.preprocessor.fit_transform(X_train, y_train)
        
        # Chu·∫©n b·ªã validation set n·∫øu ƒë∆∞·ª£c cung c·∫•p
        if X_val is not None and y_val is not None:
            print("    -> ƒêang transform d·ªØ li·ªáu validation...")
            X_val_proc = self.preprocessor.transform(X_val)
            # Th√™m v√†o fit_params ƒë·ªÉ search_strategy c√≥ th·ªÉ truy·ªÅn v√†o model
            fit_params['eval_set'] = [(X_val_proc, y_val)]

        # === B∆Ø·ªöC 2: TINH CH·ªàNH SI√äU THAM S·ªê CHO MODEL ===
        print(f"üöÄ B∆∞·ªõc 2: Tinh ch·ªânh si√™u tham s·ªë cho model...")
        
        # L·∫•y ra model g·ªëc v√† ƒë·∫£m b·∫£o search_strategy ƒëang tune tr√™n n√≥
        base_model = self.search_strategy.estimator
        self.search_strategy.estimator = base_model
        
        # Ch·∫°y tuning tr√™n d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω
        self.search_strategy.fit(X_train_proc, y_train, **fit_params)
        
        # L·∫•y ra model t·ªët nh·∫•t ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
        best_model_only = self.search_strategy.best_estimator_

        # # In v√† log k·∫øt qu·∫£ tuning
        best_params = self.search_strategy.best_params_
        print("\n=== C√°c tham s·ªë t·ªët nh·∫•t t√¨m ƒë∆∞·ª£c ===")
        print(best_params)

        scoring_metric = self.search_strategy.scoring or 'score'
        print(f"Best CV {scoring_metric}: {self.search_strategy.best_score_:.4f}")

        if self.manage_run:
            mlflow.log_params(best_params)
            mlflow.log_metric("best_cv_score", self.search_strategy.best_score_)

        # üîç Ki·ªÉm tra s·ªë c√¢y th·ª±c t·∫ø khi d√πng early stopping
        best_model_only = self.search_strategy.best_estimator_
        if hasattr(best_model_only, "best_iteration") and best_model_only.best_iteration is not None:
            actual_estimators = best_model_only.best_iteration
            print(f"‚úÖ Early Stopping ƒë√£ k√≠ch ho·∫°t! S·ªë c√¢y t·ªëi ∆∞u: {actual_estimators}")
            if self.manage_run:
                mlflow.log_metric("actual_n_estimators", actual_estimators)
        else:
            print("‚ÑπÔ∏è Early Stopping kh√¥ng ƒë∆∞·ª£c k√≠ch ho·∫°t. Model ƒë√£ ch·∫°y h·∫øt s·ªë c√¢y `n_estimators`.")

            
        # === B∆Ø·ªöC 3: L·∫ÆP R√ÅP PIPELINE CU·ªêI C√ôNG ===
        print("\nüîß B∆∞·ªõc 3: L·∫Øp r√°p pipeline ho√†n ch·ªânh cho production...")
        
        # Gh√©p preprocessor ƒë√£ ƒë∆∞·ª£c fit v√† model t·ªët nh·∫•t ƒë√£ ƒë∆∞·ª£c fit
        steps = [('preprocessor', self.preprocessor)]
        if self.sampler:
            steps.append(('sampler', self.sampler))
        steps.append(('clf', best_model_only))
        
        # T·∫°o pipeline cu·ªëi c√πng m√† kh√¥ng c·∫ßn .fit() l·∫°i
        final_pipeline = ImPipeline(steps)
        
        # G√°n v√†o thu·ªôc t√≠nh c·ªßa class ƒë·ªÉ c√≥ th·ªÉ s·ª≠ d·ª•ng sau n√†y
        self.best_estimator_ = final_pipeline
        self.pipeline = final_pipeline

        # Log pipeline ho√†n ch·ªânh v√†o MLflow
        if self.manage_run:
            print("üì¶ Logging pipeline cu·ªëi c√πng v√†o MLflow...")
            self.log_best_model(X_train.dropna())

        print("\n‚úÖ Quy tr√¨nh fit r·ªùi r·∫°c ho√†n t·∫•t. Pipeline ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng.")
        return self
    
try:
    import surprise   
    from surprise import SVD, SVDpp, NMF, SlopeOne, Dataset, Reader, accuracy
    from surprise.model_selection import train_test_split, GridSearchCV
    from joblib import Parallel, delayed
    SURPRISE_INSTALLED = True
    print("‚úÖ Th∆∞ vi·ªán 'surprise' ƒë√£ ƒë∆∞·ª£c t√¨m th·∫•y.")
except ImportError:
    SURPRISE_INSTALLED = False
    print("‚ö†Ô∏è C·∫£nh b√°o: Th∆∞ vi·ªán 'surprise' kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t. C√°c ch·ª©c nƒÉng RecSys s·∫Ω kh√¥ng kh·∫£ d·ª•ng.")
if SURPRISE_INSTALLED:
    class SurpriseWrapper(mlflow.pyfunc.PythonModel):
        """L·ªõp wrapper ƒë·ªÉ MLflow c√≥ th·ªÉ l√†m vi·ªác v·ªõi model Surprise."""
        def load_context(self, context):
            self.n_jobs = os.cpu_count() - 1 if os.cpu_count() > 1 else 1
            self.model = surprise.dump.load(context.artifacts["surprise_model"])[1]
        def predict(self, context, model_input):
            user_ids = model_input['userID'].tolist()
            item_ids = model_input['itemID'].tolist()
            tasks = (delayed(self.model.predict)(uid, iid) for uid, iid in zip(user_ids, item_ids))
            predictions_obj = Parallel(n_jobs=self.n_jobs)(tasks)
            return np.array([pred.est for pred in predictions_obj])

    class RecSysModelTuner:
        """
        Class t·ªïng qu√°t ƒë·ªÉ ch·∫°y m·ªôt th·ª≠ nghi·ªám ho√†n ch·ªânh cho m·ªôt model recommender system,
        bao g·ªìm tuning, training, evaluation v√† logging v√†o MLflow.
        """
        def __init__(self, model_class: Any, run_name: str, model_family: str, reg_model_name: str, param_grid: Optional[Dict] = None,pip_requirements: Optional[list] = None,  # <-- TH√äM D√íNG N√ÄY
                    conda_env: Optional[str] = None,
                    tags: Optional[Dict[str, str]] = None):
            self.model_class = model_class
            self.run_name = run_name
            self.model_family = model_family
            self.reg_model_name = reg_model_name
            self.param_grid = param_grid
            if pip_requirements and conda_env:
                raise ValueError("Ch·ªâ c√≥ th·ªÉ cung c·∫•p 'pip_requirements' ho·∫∑c 'conda_env', kh√¥ng ph·∫£i c·∫£ hai.")
            self.pip_requirements = pip_requirements
            self.conda_env = conda_env
            self.tags = tags if tags is not None else {}

        def _cleanup(self):
            """√âp bu·ªôc garbage collection ƒë·ªÉ gi·∫£i ph√≥ng RAM."""
            print("\nüßπ Running garbage collection...")
            gc.collect()
            print("üëç Memory cleanup complete.")

        def run(self, data, full_trainset, trainset, testset, input_example,**extra_params):
            """
            Th·ª±c thi to√†n b·ªô flow cho model ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh.
            """
            client = MlflowClient()
            with mlflow.start_run(run_name=self.run_name, nested=True):
                try:
                    print(f"\n--- B·∫Øt ƒë·∫ßu: {self.run_name} ---")
                    mlflow.set_tag("algorithm_family", self.model_family)
                    if extra_params:
                        mlflow.log_params(extra_params)
                    best_params = {}
                    if self.param_grid:
                        mlflow.set_tag("tuning", "GridSearchCV")
                        gs = GridSearchCV(self.model_class, self.param_grid, measures=['rmse'], cv=3, n_jobs=-1)
                        gs.fit(data)
                        best_params = gs.best_params['rmse']
                        mlflow.log_params(best_params)
                        mlflow.log_metric("best_cv_rmse", gs.best_score['rmse'])
                        print(f"  Tuning complete. Best CV RMSE: {gs.best_score['rmse']:.4f}")
                    else:
                        mlflow.set_tag("tuning", "skipped")
                        print("  No param_grid provided. Skipping tuning.")

                    final_algo = self.model_class(**best_params)
                    final_algo.fit(full_trainset)
                    
                    predictions_test = final_algo.test(testset)
                    test_rmse = accuracy.rmse(predictions_test, verbose=False)
                    test_mae = accuracy.mae(predictions_test, verbose=False)
                    
                    trainset_for_eval = trainset.build_testset()
                    predictions_train = final_algo.test(trainset_for_eval)
                    train_rmse = accuracy.rmse(predictions_train, verbose=False)
                    train_mae = accuracy.mae(predictions_train, verbose=False)

                    mlflow.log_metrics({"test_rmse": test_rmse, "test_mae": test_mae, "train_rmse": train_rmse, "train_mae": train_mae})
                    
                    with tempfile.NamedTemporaryFile(suffix=".pkl") as tmp:
                        surprise.dump.dump(tmp.name, algo=final_algo)
                        utils_abs_path = os.path.abspath(__file__)
                        print(f"--- DEBUG: Absolute path for code_paths: {utils_abs_path}") # In ra ƒë·ªÉ ki·ªÉm tra
                        
                        from mlflow.types.schema import Schema, ColSpec, TensorSpec
                        import numpy as np

                        # 1. ƒê·ªãnh nghƒ©a Input Schema (Kh·ªõp v·ªõi file MLmodel)
                        input_schema = Schema([
                            ColSpec("string", "userID"),
                            ColSpec("long", "itemID")
                        ])

                        # 2. ƒê·ªãnh nghƒ©a Output Schema (√âp bu·ªôc n√≥ ph·∫£i l√† TENSOR)
                        # ƒê√¢y l√† d√≤ng v√° l·ªói 'float' object
                        # N√≥ n√≥i: "Output l√† m·ªôt array 1 chi·ªÅu [-1] ch·ª©a c√°c s·ªë np.float64"
                        output_schema = Schema([
                            TensorSpec(np.dtype(np.float64), [-1])
                        ])

                        # 3. T·∫°o Signature th·ªß c√¥ng
                        manual_signature = mlflow.models.ModelSignature(inputs=input_schema, outputs=output_schema)
                        print("  Successfully created manual signature (forcing output as Tensor).")
                        mlflow.pyfunc.log_model(
                            name=f"{self.run_name}_model",
                            code_paths=[utils_abs_path],
                            python_model=SurpriseWrapper(),
                            artifacts={"surprise_model": tmp.name},
                            input_example=input_example,
                            signature=manual_signature,
                            registered_model_name=self.reg_model_name,
                            pip_requirements=self.pip_requirements, # <-- TH√äM D√íNG N√ÄY
                            conda_env=self.conda_env
                        )
                    print(f"  ‚úÖ {self.run_name} | Train RMSE: {train_rmse:.4f} | Test RMSE: {test_rmse:.4f}")
                    if self.tags:
                            print(f"  Setting tags for Registered Model '{self.reg_model_name}': {self.tags}")
                            for key, value in self.tags.items():
                                try:
                                    client.set_registered_model_tag(self.reg_model_name, key, value)
                                    print(f"    Set tag: {key} = {value}")
                                except Exception as tag_error:
                                    print(f"    ‚ö†Ô∏è Failed to set tag '{key}': {tag_error}")
                except Exception as e:
                    print(f"  ‚ùå An error occurred in {self.run_name}: {e}")
                    mlflow.set_tag("status", "failed")
                    mlflow.set_tag("error", str(e))
                
                finally:
                    self._cleanup()

    
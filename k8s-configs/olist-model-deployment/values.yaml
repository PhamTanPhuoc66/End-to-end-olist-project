#  Báº­t cháº¿ Ä‘á»™ InferenceService (KServe)
inferenceService:
  enabled: true

#  Cáº¥u hÃ¬nh Image cá»§a báº¡n
image:
  repository: phamtanphuoc/champion-models
  pullPolicy: IfNotPresent
  # Äáº·t tag cá»¥ thá»ƒ (vÃ­ dá»¥: "1.0.0") sáº½ tá»‘t hÆ¡n "latest"
  # Ä‘á»ƒ Keel cÃ³ thá»ƒ theo dÃµi phiÃªn báº£n má»›i
  tag: ""
modelName: ""
mlflowEnvManager: "local"
mlserverPath: "/usr/local/bin/mlserver"
# Cáº¥u hÃ¬nh Port
# ÄÃ¢y lÃ  port mÃ  á»©ng dá»¥ng/model cá»§a báº¡n cháº¡y BÃŠN TRONG container
containerPort: 8080

# Cáº¥u hÃ¬nh Scale (Quan trá»ng nháº¥t)
autoscaling:
  # KÃ­ch hoáº¡t scale-to-zero
  minReplicas: 0 
  
  # Giá»›i háº¡n scale-up
  maxReplicas: 2 
  
  # Má»¥c tiÃªu scale-up: Khi Pod Ä‘áº¡t 80% CPU
  # KServe/Knative cÅ©ng scale dá»±a trÃªn "concurrency" (sá»‘ request Ä‘á»“ng thá»i)
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

#  Cáº¥u hÃ¬nh Service Account (Báº£o máº­t)
serviceAccount:
  create: true
  automount: false
  name: "" # Äá»ƒ Helm tá»± táº¡o tÃªn

# # ğŸ¤– Cáº¥u hÃ¬nh Keel (Tá»± Ä‘á»™ng cáº­p nháº­t)
# keel:
#   enabled: true
#   policy: "force" 
#   trigger: "poll"
#   pollSchedule: "@every 5m"



# Táº®T HPA (HorizontalPodAutoscaler) truyá»n thá»‘ng
autoscaling_legacy:
  enabled: false # Äá»•i tÃªn Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t vá»›i autoscaling á»Ÿ trÃªn

# Táº®T Ingress truyá»n thá»‘ng
ingress:
  enabled: false

# Táº®T Service truyá»n thá»‘ng
service:
  enabled: false
  type: ClusterIP
  port: 80
  targetPort: 8080 # Äá»•i tÃªn thÃ nh 'containerPort' á»Ÿ trÃªn cho rÃµ rÃ ng

httpRoute:
  enabled: false